{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73928d00",
   "metadata": {},
   "source": [
    "### Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49a542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#mandatory for correct load and save of files\n",
    "%cd /Users/paolobonomi/work/python/capsnet\n",
    "\n",
    "# for project class\n",
    "import sys\n",
    "sys.path.append(\"./src\")\n",
    "\n",
    "from setup import Setup # set up model and dataset\n",
    "import perfu # performance function such as confusion matrix etc...\n",
    "import printer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d895f3",
   "metadata": {},
   "source": [
    "### Retrieve model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bea27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_data(x, y, shuffle):\n",
    "    x_ = x\n",
    "    y_ = y\n",
    "\n",
    "    x_ = x_ / 255.0\n",
    "    x_ = tf.cast(x_, dtype=tf.float32)\n",
    "    x_ = tf.expand_dims(x_, axis=-1)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x_, y_))\n",
    "    if shuffle:\n",
    "\n",
    "        dataset = dataset.shuffle(buffer_size=len(dataset), reshuffle_each_iteration=True)\n",
    "\n",
    "    dataset = dataset.batch(batch_size=64)\n",
    "    return x_, y_, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd49517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as spio\n",
    "import numpy as np\n",
    "\n",
    "#test set is 10k per batch, trainning set is 50k per batch\n",
    "\n",
    "def loadmat(filename):\n",
    "    '''\n",
    "    this function should be called instead of direct spio.loadmat\n",
    "    as it cures the problem of not properly recovering python dictionaries\n",
    "    from mat files. It calls the function check keys to cure all entries\n",
    "    which are still mat-objects\n",
    "    '''\n",
    "    data = spio.loadmat(filename, struct_as_record=False, squeeze_me=True)\n",
    "    return _check_keys(data)\n",
    "\n",
    "\n",
    "def _check_keys(dict):\n",
    "    '''\n",
    "    checks if entries in dictionary are mat-objects. If yes\n",
    "    todict is called to change them to nested dictionaries\n",
    "    '''\n",
    "    for key in dict:\n",
    "        if isinstance(dict[key], spio.matlab.mio5_params.mat_struct):\n",
    "            dict[key] = _todict(dict[key])\n",
    "    return dict        \n",
    "\n",
    "\n",
    "def _todict(matobj):\n",
    "    '''\n",
    "    A recursive function which constructs from matobjects nested dictionaries\n",
    "    '''\n",
    "    dict = {}\n",
    "    for strg in matobj._fieldnames:\n",
    "        elem = matobj.__dict__[strg]\n",
    "        if isinstance(elem, spio.matlab.mio5_params.mat_struct):\n",
    "            dict[strg] = _todict(elem)\n",
    "        else:\n",
    "            dict[strg] = elem\n",
    "    return dict\n",
    "\n",
    "def _unpack(dataset):\n",
    "    ans_set = dataset['affNISTdata']['label_int']\n",
    "    img_set = dataset['affNISTdata']['image']\n",
    "    trans = dataset['affNISTdata']['human_readable_transform']\n",
    "    \n",
    "    img_set = np.transpose(img_set)\n",
    "    img_set = np.reshape(img_set, (-1, 40, 40))\n",
    "    ans_set = ans_set.astype(np.uint8)\n",
    "\n",
    "    return img_set, ans_set, trans\n",
    "\n",
    "def load(train):\n",
    "    s = \"training\" if train else \"test\"\n",
    "\n",
    "    if train:\n",
    "        path = './data/affNIST/'+s+'_batches/1.mat'\n",
    "        data = _unpack(loadmat(path))\n",
    "    else:\n",
    "        path = './data/affNIST/'+s+'_batches/1.mat'\n",
    "        img_set, ans_set, trans = _unpack(loadmat(path))\n",
    "\n",
    "    return img_set, ans_set, trans\n",
    "\n",
    "def load_affnist_transformations(train):\n",
    "    s = \"training\" if train else \"test\"\n",
    "\n",
    "    if train:\n",
    "        path = './data/affNIST/'+s+'_batches/1.mat'\n",
    "        data = _unpack(loadmat(path))\n",
    "    else:\n",
    "        path = './data/affNIST/'+s+'_batches/1.mat'\n",
    "        img_set, ans_set, trans = _unpack(loadmat(path))\n",
    "\n",
    "    return trans\n",
    "\n",
    "def load_MNIST(train):\n",
    "    s = \"training\" if train else \"test\"\n",
    "    path = './data/affNIST/originals/'+s+'.mat'\n",
    "    img_set, ans_set, trans = _unpack(loadmat(path))\n",
    "    return img_set, ans_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d813e17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as fn\n",
    "\n",
    "def convert_to_torch(img):\n",
    "    rx = torch.from_numpy(img)\n",
    "    rx = torch.unsqueeze(rx, 0)\n",
    "    return rx\n",
    "\n",
    "def convert_to_tensor(img):\n",
    "    rx = tf.convert_to_tensor(img, dtype=tf.dtypes.float32)\n",
    "    rx = np.reshape(rx, [1, 40, 40])\n",
    "    return rx\n",
    "\n",
    "def apply_scaling(img, x, y, mode):\n",
    "    i = int(40*y)\n",
    "    j = int(40*x)\n",
    "    rx = fn.resize(img, size=[ i, j ], interpolation=mode)\n",
    "    rx = fn.center_crop(rx, [40, 40])\n",
    "    return rx\n",
    "\n",
    "def apply_transformation(img, data, id, mode=transforms.InterpolationMode.BILINEAR):\n",
    "    rotation = data[0][id] #counter clock wise between -20 and +20\n",
    "    shearing = data[1][id] #shearing between -0.2 and +0.2. if shear 1 horiz line turns into 45 degree line\n",
    "    y_scale = data[2][id]\n",
    "    x_scale = data[3][id] # between 0.8 (shrinking by 20%) and 1.2 (making 20% larger).\n",
    "    v_trasl = data[4][id]\n",
    "    h_trasl = data[5][id] # \n",
    "    \n",
    "    rx = convert_to_torch(img)    \n",
    "    rx = fn.affine(rx, rotation*-1, [0, 0], 1, [0, shearing*-45], interpolation=mode)\n",
    "    rx = apply_scaling(rx, x_scale, y_scale, mode)\n",
    "    #rx = fn.affine(rx, 0, [h_trasl*0.4, v_trasl*0.4], 1, 0, interpolation=mode)\n",
    "\n",
    "    rx = convert_to_tensor(rx)\n",
    "    rx = tf.reshape(rx, [40, 40])\n",
    "    return rx\n",
    "\n",
    "def create_affnist(train):\n",
    "    x, y = load_MNIST(train)\n",
    "    t = load_affnist_transformations(train)\n",
    "\n",
    "    for i in range(0, x.shape[0]): \n",
    "        x[i] = apply_transformation(x[i], t, i)\n",
    "        \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8268a1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = load_MNIST(False)\n",
    "aff = load(False)\n",
    "my_aff = create_affnist(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7ab74e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for id in range(0, 10):\n",
    "    original_image = mnist[0][id]\n",
    "    affnist_image = aff[0][id]\n",
    "    my_image = my_aff[0][id]\n",
    "\n",
    "    printer.print_image(original_image, mnist[1][id], 40)\n",
    "    printer.print_image(my_image, my_aff[1][id], 40)\n",
    "    printer.print_image(affnist_image, aff[1][id], 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49460f99",
   "metadata": {},
   "source": [
    "# TEST IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e069c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Setup.GEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02c5397",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_id = Setup.GEN[0]\n",
    "model_version = \"_3e-5\"\n",
    "dataset_version = \"_v1\"\n",
    "\n",
    "setup = Setup()\n",
    "\n",
    "#load original mnist dataset and model\n",
    "x_t, y_t, b_t = setup.load_data(Setup.GEN[0], train=True, version=dataset_version, create=False)\n",
    "model = setup.init_model(model_id, model_version, x_t, y_t)\n",
    "model3 = setup.init_model(model_id, model_version, x_t, y_t, \"v3\")\n",
    "\n",
    "#load affnist\n",
    "x, y, b = setup.load_data(Setup.GEN[1], train=False, version=dataset_version, create=False)\n",
    "\n",
    "#load mnist\n",
    "x_2, y_2, b_2 = setup.load_data(Setup.GEN[0], train=False, version=dataset_version, create=False)\n",
    "\n",
    "#recreate affnist\n",
    "m_x, m_y = create_affnist(False)\n",
    "m_x, m_y, m_b = _process_data(m_x, m_y, False) \n",
    "\n",
    "setup.load_ckpt(model, 1)\n",
    "setup.load_ckpt(model3, 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5b9384",
   "metadata": {},
   "source": [
    "# Model v2 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2e1a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aff_acc = setup.get_accuracy(model, b, setup.get_total_images(x))\n",
    "#print(aff_acc)\n",
    "#  0.2143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93f3dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnist_acc = setup.get_accuracy(model, b_2, setup.get_total_images(x_2))\n",
    "#print(mnist_acc)\n",
    "#  0.9915"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd06647c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval. accuracy :  99%|███████████████████████████████████████████████████████████████████████████████████████████████████▎| 156/157 [07:59<00:03,  3.07s/it]2023-02-28 12:50:16.664334: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "Eval. accuracy : 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [08:01<00:00,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "my_aff_acc = setup.get_accuracy(model, m_b, setup.get_total_images(m_x))\n",
    "print(my_aff_acc)\n",
    "\n",
    "# interpolation mode BILINEAR = 0.2114\n",
    "# interpolation mode NEAREST = 0.2127\n",
    "# interpolation mode NEAREST = 0.2113 - no shearing\n",
    "# interpolation mode NEAREST = 0.2189 - no scaling\n",
    "# interpolation mode NEAREST = 0.9559 - no transaltion\n",
    "# interpolation mode BILINEAR = 0.xxxx - no transaltion\n",
    "# interpolation mode NEARESR = 0.8766 - traslation only at 0.2 percent then original\n",
    "# interpolation mode NEARESR = 0.6259 - traslation only at 0.4 percent then original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca3ab89",
   "metadata": {},
   "source": [
    "# Model v3 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ad94a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aff_acc = setup.get_accuracy(model3, b, setup.get_total_images(x))\n",
    "#print(aff_acc)\n",
    "#  0.2577"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c6e26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnist_acc = setup.get_accuracy(model3, b_2, setup.get_total_images(x_2))\n",
    "#print(mnist_acc)\n",
    "#  0.9947"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb97c603",
   "metadata": {},
   "outputs": [],
   "source": [
    "printer.print_image(m_x[0], 0, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665744eb",
   "metadata": {},
   "source": [
    "### Perfomance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a75e6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "printer.pretty_experiment_overview(setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644a8eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "should_create_matrix = True\n",
    "flag_only_test = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba22fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_train = train_dataset_type.replace(\"_\", \" \")\n",
    "p_test = test_dataset_type.replace(\"_\", \" \")\n",
    "\n",
    "if should_create_matrix:\n",
    "    %store -r matrix_dict\n",
    "    \n",
    "    if flag_only_test:\n",
    "        cm_train = matrix_dict[str(epochs)+\"_\"+train_dataset_type]\n",
    "    else:\n",
    "        cm_train = perfu.get_confusion_mat(model.predict, dataset, \"train\")\n",
    "        matrix_dict[str(epochs)+\"_\"+train_dataset_type] = cm_train\n",
    "    \n",
    "    cm_test = perfu.get_confusion_mat(model.predict, testing, \"test\")\n",
    "    matrix_dict[str(epochs)+\"_\"+train_dataset_type+\"_\"+test_dataset_type] = cm_test\n",
    "    \n",
    "    %store matrix_dict\n",
    "else:\n",
    "    %store -r matrix_dict\n",
    "    cm_test = matrix_dict[str(epochs)+\"_\"+train_dataset_type+\"_\"+test_dataset_type]\n",
    "    cm_train = matrix_dict[str(epochs)+\"_\"+train_dataset_type]  \n",
    "    \n",
    "acc_train = perfu.get_accuracy(perfu.normalize_matrix( cm_train, no_train_images))\n",
    "acc_test = perfu.get_accuracy(perfu.normalize_matrix( cm_test, no_test_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe79967e",
   "metadata": {},
   "source": [
    "#### Testing Confusion Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95039c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "values, columns, index = perfu.get_confusion_table(cm_test, no_test_images)\n",
    "printer.print_confusion_tables(values, columns, index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a757c5ea",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31470912",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "######## TRAIN\n",
    "\n",
    "mat = cm_train\n",
    "n = no_train_images\n",
    "s = '{0} ({1} epochs)'.format(p_train, epochs)\n",
    "\n",
    "printer.print_matrix( perfu.normalize_matrix(mat, n),\n",
    "                        'Normalized on total images(%)', \n",
    "                        s, \n",
    "                        '{0} train'.format(p_train), \n",
    "                         n)\n",
    "\n",
    "printer.print_matrix( perfu.normalize_matrix_on_row(mat),\n",
    "                        'Normalized on on tot images in row(%)', \n",
    "                        s, \n",
    "                        '{0} train'.format(p_train),  \n",
    "                         n,\n",
    "                         row_labels=printer.get_sum_row_matrix_label(mat))\n",
    "\n",
    "printer.print_matrix( perfu.normalize_matrix_on_columns(mat),\n",
    "                        'Normalized on tot images in column(%)', \n",
    "                        s, \n",
    "                        '{0} train'.format(p_train),  \n",
    "                         n,\n",
    "                         col_labels=printer.get_sum_colum_matrix_label(mat))\n",
    "\n",
    "####### TEST\n",
    "\n",
    "mat = cm_test\n",
    "n = no_test_images\n",
    "\n",
    "printer.print_matrix( perfu.normalize_matrix(mat, n),\n",
    "                        'Normalized on total images(%)', \n",
    "                        s, \n",
    "                        '{0} test'.format(p_test),  \n",
    "                         no_test_images)\n",
    "\n",
    "printer.print_matrix( perfu.normalize_matrix_on_row(mat),\n",
    "                        'Normalized on on tot images in row(%)', \n",
    "                        s, \n",
    "                        '{0} test'.format(p_test),  \n",
    "                         n,\n",
    "                         row_labels=printer.get_sum_row_matrix_label(mat))\n",
    "\n",
    "printer.print_matrix( perfu.normalize_matrix_on_columns(mat),\n",
    "                        'Normalized on tot images in column(%)', \n",
    "                        s, \n",
    "                        '{0} test'.format(p_test),  \n",
    "                         n,\n",
    "                         col_labels=printer.get_sum_colum_matrix_label(mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd4840b",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9d22ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "printer.print_accuracy(acc_train, acc_test, no_train_images, no_test_images, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc86cca1",
   "metadata": {},
   "source": [
    "### Error cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9b4729",
   "metadata": {},
   "outputs": [],
   "source": [
    "off = 44\n",
    "n = 110\n",
    "idx, pred = perfu.get_error_index(model, X_test[off:off+n], y_test[off:off+n], off)\n",
    "\n",
    "print(idx)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061c4de7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(idx)):\n",
    "    img = idx[i]\n",
    "    printer.print_image_and_prediction(X_test[img], y_test[img], pred[i], 40 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d25f921",
   "metadata": {},
   "source": [
    "### Network Conv1/PrimaryCapsule Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba7c1c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "printer.print_network(model, X_test[45], y_test[45], 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c7d52f",
   "metadata": {},
   "source": [
    "### Network Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b206e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "printer.print_fixed_network_params(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "27039add6037919ceee90f8f6a1ded5e18fb50dba46fc6f2fa7bb5396680f76d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
