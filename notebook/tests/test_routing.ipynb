{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80a44220-5073-4038-a3d6-b6fab0554beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4dc350-0822-456a-a72a-948bb7eff438",
   "metadata": {},
   "source": [
    "# tf.nn.softmax\n",
    "\n",
    "Computes softmax activations.\n",
    "\n",
    "Used for multi-class predictions. The sum of all outputs generated by softmax is 1.\n",
    "\n",
    "This function performs the equivalent of\n",
    "\n",
    "\n",
    "`softmax = tf.exp(logits) / tf.reduce_sum(tf.exp(logits), axis)`\n",
    "\n",
    "# tf.multiply\n",
    "\n",
    "Returns x * y element-wise.\n",
    "\n",
    "\n",
    "ref @ https://docs.w3cub.com/tensorflow~python/tf/multiply\n",
    "\n",
    "# tf.reduce_sum\n",
    "\n",
    "Computes the sum of elements across dimensions of a tensor.\n",
    "\n",
    "Reduces input_tensor along the dimensions given in axis. Unless keepdims is true, the rank of the tensor is reduced by 1 for each entry in axis. If keepdims is true, the reduced dimensions are retained with length 1. def squash(self, s):\n",
    "        with tf.name_scope(\"SquashFunction\") as scope:\n",
    "            s_norm = tf.norm(s, axis=-1, keepdims=True)\n",
    "            return tf.square(s_norm)/(1 + tf.square(s_norm)) * s/(s_norm + epsilon)\n",
    "\n",
    "$ s_j = \\sum c_{ij}\\hat{u}_{j|i} $\n",
    "\n",
    "ref @ https://docs.w3cub.com/tensorflow~python/tf/reduce_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cfb6013-6434-4ec8-9222-d7b2500bc9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-7\n",
    "    \n",
    "def squash(s):\n",
    "    s_norm = tf.norm(s, axis=-1, keepdims=True)\n",
    "    return tf.square(s_norm)/(1 + tf.square(s_norm)) * s/(s_norm + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9d72fe7-b272-4fc3-b7ac-8f1755d85611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-01 09:21:26.693713: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-06-01 09:21:26.693802: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# ------------ COMPUTE U_HAT\n",
    "\n",
    "w_shape = (1, 1152, 10, 16, 8)\n",
    "u_shape = (1, 1152, 1, 8, 1)\n",
    "w = tf.fill(w_shape, 1.0)\n",
    "u = tf.fill(u_shape, 1.0)\n",
    "#u_hat shape: (1, 1152, 10, 16, 1)\n",
    "u_hat = tf.matmul(w, u)\n",
    "#u_hat shape: (1, 1152, 10, 16)\n",
    "u_hat = tf.squeeze(u_hat, axis=-1)\n",
    "\n",
    "# ----------- ROUTING\n",
    "\n",
    "# b.shape: (1, 1152, 10, 1)\n",
    "b = tf.zeros((1, 1152, 10, 1))\n",
    "\n",
    "for i in range(1):\n",
    "    \n",
    "    # applies softmax to the output of all DigitCaps (axis=-2 => 10)\n",
    "    # c.shape: (1, 1152, 10, 1)\n",
    "    c = tf.nn.softmax(b, axis=-2) \n",
    "    \n",
    "    # tmp.shape: (1, 1152, 10, 16)   \n",
    "    # tmp is composed by all the u_hat ( vector 16D ) multiplied element wise for it's respective coupling coefficient\n",
    "    tmp = tf.multiply(c, u_hat)\n",
    "    \n",
    "    # s.shape: (1, 1, 10, 16)\n",
    "    # sum all vectors with respect to the second dimension\n",
    "    # using the nomeclature of the paper this function sums the vectors with respect to i with j fixed\n",
    "    s = tf.reduce_sum(tmp, axis=1, keepdims=True)\n",
    "    \n",
    "    v = squash(s) # v.shape: (None, 1, 10, 16)\n",
    "    \n",
    "    agreement = tf.squeeze(tf.matmul(tf.expand_dims(u_hat, axis=-1), tf.expand_dims(v, axis=-1), transpose_a=True), [4]) # agreement.shape: (None, 1152, 10, 1)\n",
    "    \n",
    "    # Before matmul following intermediate shapes are present, they are not assigned to a variable but just for understanding the code.\n",
    "    # u_hat.shape (Intermediate shape) : (None, 1152, 10, 16, 1)\n",
    "    # v.shape (Intermediate shape): (None, 1, 10, 16, 1)\n",
    "    # Since the first parameter of matmul is to be transposed its shape becomes:(None, 1152, 10, 1, 16)\n",
    "    # Now matmul is performed in the last two dimensions, and others are broadcasted\n",
    "    # Before squeezing we have an intermediate shape of (None, 1152, 10, 1, 1)\n",
    "    \n",
    "    b += agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c23e4ec5-5e66-4cae-96bd-b5ed984778d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1152, 10, 1)\n",
      "(1, 1152, 10, 16)\n",
      "tf.Tensor(0.8, shape=(), dtype=float32)\n",
      "tf.Tensor(921.59973, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "w = tf.fill(w_shape, 1.0)\n",
    "u = tf.fill(u_shape, 1.0)\n",
    "\n",
    "w_shape = (1, 1152, 10, 16, 8)\n",
    "u_shape = (1, 1152, 1, 8, 1)\n",
    "u_hat = tf.matmul(w, u)\n",
    "u_hat = tf.squeeze(u_hat, axis=-1)\n",
    "\n",
    "#u_hat shape: (1, 1152, 10, 16) filled with 8\n",
    "\n",
    "b_shape = (1, 1152, 10, 1)\n",
    "b = tf.fill(b_shape, 1.0)\n",
    "c = tf.nn.softmax(b, axis=-2) \n",
    "#b.shape (1, 1152, 10, 1)\n",
    "print(c.shape)\n",
    "#u_hat.shape (1, 1152, 10, 16)\n",
    "print(u_hat.shape)\n",
    "#tmp.shape (1, 1152, 10, 16)\n",
    "tmp = tf.multiply(c, u_hat)\n",
    "\n",
    "print(tmp[0,0,0,0])\n",
    "\n",
    "s = tf.reduce_sum(tmp, axis=1, keepdims=True)\n",
    "\n",
    "print(s[0,0,0,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
