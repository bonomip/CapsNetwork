{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80a44220-5073-4038-a3d6-b6fab0554beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a284fea0-2137-4448-9f1e-cbcf4528c5e5",
   "metadata": {},
   "source": [
    "# W[16x8]\n",
    "\n",
    "output[..., i, j] = sum_k (a[..., i, k] * b[..., k, j]), for all indices i, j.\n",
    "\n",
    "Nella rete abbiamo un totale di $1152 * 10$ matrici W[16x8]. 1152 poichè è il numero di vettori 8D restituiti in output dal livello PrimariCaps, 10 poichè è il numero delle DigitsCaps (la rete deve riconoscere numeri da 0 a 9 quindi in totale 10 possibili valori), 16 poichè ogni DigitsCap restituisce come output un vettore 16D.\n",
    "\n",
    "Quindi si deduce che i due layer sono completamente connessi (fully connected). Cioè l'output di ogni DigitCap è condizionato da tutti gli output del layer precedente. \n",
    "\n",
    "\n",
    "Il risultato del codice seguente è un vettore a 16 dimensioni composto dal valore 8 che è il risultato della moltiplicazione di una matrice 16x8 composta da 1 con un vettore di 8 dimensioni composto da 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e92fb705-8486-4bf4-845e-c7b092435926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-01 09:21:32.114513: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-06-01 09:21:32.114593: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "w_shape = (16, 8)\n",
    "u_shape = (8, 1)\n",
    "\n",
    "w = tf.fill(w_shape, 1)\n",
    "u = tf.fill(u_shape, 1)\n",
    "\n",
    "#u_hat shape: (16, 1)\n",
    "u_hat = tf.matmul(w, u)\n",
    "#u_hat shape: (1, 16, 1)\n",
    "u_hat = tf.expand_dims(u_hat, axis=0)\n",
    "#u_hat shape: (1, 16)\n",
    "u_hat = tf.squeeze(u_hat, axis=-1)\n",
    "\n",
    "\n",
    "#il risultato è un vettore a 16D composto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9fccd7-cad8-4a2b-bd94-10331d2ee1aa",
   "metadata": {},
   "source": [
    "# FORMATO\n",
    "\n",
    "Dati due tensori $ A $ con shape $ ( a_1, \\cdots , a_k ) $ e  $ B $ con shape $ ( b_1, \\cdots , b_k) $.\n",
    "Sapendo che le dimensioni fino a ${k-2}$ incluso rappresentano la dimensione del batch, invece le ultime due descrivono le dimensioni della matrice. \n",
    "\n",
    "L'operazione $ A x B $ (A moltiplicato per B) è possibile solo se:\n",
    "\n",
    "- $ a_i = b_i $ oppure se $ a_i = 1 $ o $ b_i = 1 $\n",
    "\n",
    "- $a_k = b_{k-1} $\n",
    "\n",
    "# CODICE\n",
    "\n",
    "u_hat in questo caso è un insieme di vettori 16D. Ne abbiamo un totale di $ 1152*10 $.\n",
    "\n",
    "come nell'esempio precedente abbiamo che ogni vettore 16D è composto dal valore 8 ripetuto 16 volte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e800993-ac43-4777-af65-f3049f4a3c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1152, 10, 16])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_shape = (1152, 10, 16, 8)\n",
    "u_shape = (1152, 1, 8, 1)\n",
    "\n",
    "w = tf.fill(w_shape, 1)\n",
    "u = tf.fill(u_shape, 1)\n",
    "\n",
    "#u_hat shape: (1152, 10, 16, 1)\n",
    "u_hat = tf.matmul(w, u)\n",
    "#u_hat shape: (1152, 10, 16)\n",
    "u_hat = tf.squeeze(u_hat, axis=-1)\n",
    "u_hat.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
